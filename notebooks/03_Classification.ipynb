{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86db5f20",
   "metadata": {},
   "source": [
    "## Disease Prediction Using Classification\n",
    "\n",
    "In this notebook, we build a classification model to **predict the disease (prognosis)** based on a patient's symptoms, weather conditions, and other features such as age and gender.\n",
    "\n",
    "### üîç Why Classification?\n",
    "\n",
    "This task is a classic **supervised learning problem**: we have input features and a known output label (`prognosis`). Classification allows us to train a model that can learn from historical cases and make accurate predictions on new patient data.\n",
    "\n",
    "For example:\n",
    "- If a patient presents with **headache, vomiting, and high temperature**, the model may predict a high probability of **Migraine**.\n",
    "- If a patient has **chest pain, high blood pressure, and humidity is high**, it might predict **Heart Attack**.\n",
    "\n",
    "These predictions could support **clinical decision-making**, early detection, or patient triage.\n",
    "\n",
    "### üîó How Pattern Mining Helps\n",
    "\n",
    "Earlier, we used pattern mining (FP-Growth) to identify frequent symptom combinations linked to specific diseases. Those patterns help:\n",
    "- Highlight **strong symptom-disease associations** (e.g., `{headache, vomiting} ‚Üí Migraine`)\n",
    "- Guide **feature importance awareness** before modeling\n",
    "- Validate whether the model is learning similar relationships\n",
    "\n",
    "### ‚ùå Why Not Clustering or Outlier Detection?\n",
    "\n",
    "- **Clustering** is unsupervised and used to explore hidden groupings ‚Äî but we already know the disease labels.\n",
    "- **Outlier detection** identifies rare or unusual data points ‚Äî useful for anomaly detection, not disease prediction.\n",
    "\n",
    "Therefore, **classification** is the most appropriate and effective approach for our goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35fc7b4",
   "metadata": {},
   "source": [
    "## Step 1: Load Preprocessed Data\n",
    "\n",
    "We begin by loading the cleaned and scaled dataset from the preprocessing step. This dataset includes both binary symptom indicators and continuous features (e.g., age, weather) that have been normalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06458990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (4981, 49)\n",
      "Target classes: 11 ‚Üí ['Heart Attack' 'Influenza' 'Dengue' 'Sinusitis' 'Eczema' 'Common Cold'\n",
      " 'Heat Stroke' 'Migraine' 'Malaria' 'Arthritis' 'Stroke']\n",
      "\n",
      "First few rows of the dataset:\n",
      "        Age  Gender  Temperature (C)  Humidity  Wind Speed (km/h)  nausea  \\\n",
      "0  0.030303       1         0.729691  0.586755           0.264610       1   \n",
      "1  0.545455       0         0.654889  0.364238           0.486594       0   \n",
      "2  0.444444       0         0.515404  0.709272           0.136890       0   \n",
      "3  0.050505       0         0.933323  0.380132           0.575202       1   \n",
      "4  0.696970       0         0.593129  0.793377           0.572230       0   \n",
      "\n",
      "   joint_pain  abdominal_pain  high_fever  chills  ...  sinus_headache  \\\n",
      "0           0               0           0       0  ...               0   \n",
      "1           0               0           0       1  ...               0   \n",
      "2           0               0           0       0  ...               0   \n",
      "3           0               0           1       0  ...               0   \n",
      "4           0               0           0       0  ...               1   \n",
      "\n",
      "   facial_pain  shortness_of_breath  reduced_smell_and_taste  skin_irritation  \\\n",
      "0            0                    1                        0                0   \n",
      "1            0                    0                        0                0   \n",
      "2            0                    0                        0                0   \n",
      "3            0                    0                        0                0   \n",
      "4            1                    0                        0                0   \n",
      "\n",
      "   itchiness  throbbing_headache  confusion  back_pain  knee_ache  \n",
      "0          0                   0          0          0          0  \n",
      "1          0                   0          0          0          0  \n",
      "2          0                   0          0          0          0  \n",
      "3          0                   0          0          0          0  \n",
      "4          0                   0          0          0          0  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_csv(\"../data/processed/cleaned_data.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"prognosis\"])\n",
    "y = df[\"prognosis\"]\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target classes: {y.nunique()} ‚Üí {y.unique()[:11]}\")\n",
    "# Display first few rows of the dataset\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9457f2b",
   "metadata": {},
   "source": [
    "## Step 2: Split Data into Training and Test Sets\n",
    "\n",
    "To evaluate our classification model, we split the data into two parts:\n",
    "\n",
    "- **Training set**: Used to train the model (80% of the data).\n",
    "- **Test set**: Used to evaluate how well the model performs on unseen data (20%).\n",
    "\n",
    "We use `train_test_split()` from `scikit-learn` with the following parameters:\n",
    "\n",
    "- `X`: All the input features (symptoms, age, weather data, etc.).\n",
    "- `y`: The target labels (i.e., the `prognosis` column ‚Äî the disease to be predicted).\n",
    "- `test_size=0.2`: Allocates 20% of the data for testing.\n",
    "- `stratify=y`: Ensures that each class (disease) is proportionally represented in both train and test sets.\n",
    "- `random_state=42`: Ensures reproducibility by fixing the random seed.\n",
    "\n",
    "This gives us:\n",
    "\n",
    "- `X_train`: Feature values for training.\n",
    "- `X_test`: Feature values for testing.\n",
    "- `y_train`: Target labels for training.\n",
    "- `y_test`: Target labels for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee7cac",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ec16e",
   "metadata": {},
   "source": [
    "## Step 3: Train a K-Nearest Neighbors (KNN) Classifier\n",
    "\n",
    "We train a KNN model using `k = 5`, which means the prediction is based on the 5 closest neighbors in the training data. KNN is a distance-based method, so it's important that continuous features are properly scaled ‚Äî which was done during preprocessing.\n",
    "\n",
    "### Introduction to K-Nearest Neighbors (KNN)\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a **non-parametric** and **instance-based** learning algorithm. It works by comparing a new, unseen data point to the labeled data points in the training set. Specifically, it looks for the `k` closest data points (neighbors) in terms of feature similarity ‚Äî typically using a distance metric like Euclidean distance ‚Äî and assigns the most common class label among those neighbors to the new point.\n",
    "\n",
    "This method is effective when similar cases tend to have similar outcomes, making it highly interpretable and intuitive.\n",
    "\n",
    "In our context, KNN is useful because it can naturally take into account the **similarity of symptoms and environmental conditions** (like temperature or humidity) across patients. For example, if previous patients with high fever, chest pain, and similar weather exposure were diagnosed with dengue, KNN can use those historical patterns to make accurate predictions for new cases. It doesn't assume a fixed model form, which is helpful given the complex, multi-factor nature of medical data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac51da",
   "metadata": {},
   "source": [
    "### üîç Visual Explanation of KNN (Illustration Only)\n",
    "\n",
    "To help visualize how the **K-Nearest Neighbors algorithm** works, the following plot shows a **synthetic 2D dataset** and a new data point being classified based on its 5 nearest neighbors.\n",
    "\n",
    "> ‚ö†Ô∏è **Note**: This example is **purely illustrative**. It uses **artificial data** for visualization purposes and is not based on the actual medical dataset used in this project.\n",
    "\n",
    "The plot demonstrates:\n",
    "- How KNN uses distance to find the `k` nearest points.\n",
    "- How the predicted class is chosen by **majority vote** among neighbors.\n",
    "- The visual connection between the new sample and its neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670c3ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Generate simple 2D data for demonstration\n",
    "X, y = make_classification(\n",
    "    n_samples=200, n_features=2, n_informative=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, n_classes=3, random_state=42\n",
    ")\n",
    "\n",
    "colors = ['red', 'green', 'blue']\n",
    "class_labels = ['Class 0', 'Class 1', 'Class 2']\n",
    "\n",
    "# Train KNN model\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# New sample\n",
    "new_point = np.array([[0, 0]])\n",
    "predicted_class = knn.predict(new_point)[0]\n",
    "\n",
    "# Find k nearest neighbors\n",
    "nn = NearestNeighbors(n_neighbors=k)\n",
    "nn.fit(X)\n",
    "distances, indices = nn.kneighbors(new_point)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot existing points\n",
    "for class_value in np.unique(y):\n",
    "    plt.scatter(\n",
    "        X[y == class_value, 0], X[y == class_value, 1],\n",
    "        color=colors[class_value], label=class_labels[class_value], alpha=0.6\n",
    "    )\n",
    "\n",
    "# Highlight nearest neighbors\n",
    "for idx in indices[0]:\n",
    "    plt.plot([X[idx, 0], new_point[0, 0]], [X[idx, 1], new_point[0, 1]], \n",
    "             'k--', alpha=0.5)\n",
    "\n",
    "# Plot new point\n",
    "plt.scatter(new_point[0][0], new_point[0][1], color='black', edgecolor='white', \n",
    "            marker='X', s=200, label='New Sample')\n",
    "\n",
    "# Annotate prediction\n",
    "plt.text(new_point[0][0] + 0.3, new_point[0][1], \n",
    "         f\"Predicted: Class {predicted_class}\", fontsize=12, color='black')\n",
    "\n",
    "plt.title(f\"KNN Decision (k={k}) with Nearest Neighbors Highlighted\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c7276",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204049be",
   "metadata": {},
   "source": [
    "## Step 3.1: Evaluate Model Performance\n",
    "\n",
    "We evaluate the KNN model using standard classification metrics:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision / Recall / F1-Score**: Per-class evaluation\n",
    "- **Confusion Matrix**: Visual breakdown of true vs predicted labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355af37",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def evaluate_model(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"\n",
    "    Evaluates a classification model by printing metrics and plotting a normalized confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Ground truth labels\n",
    "    - y_pred: Predicted labels\n",
    "    - class_names: List of class names in the order of encoded labels\n",
    "    - save_path: Path to save the confusion matrix image\n",
    "    \"\"\"\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    # Format labels: e.g. 0: Arthritis, 1: Common Cold, ...\n",
    "    labels = [f\"{i}: {name}\" for i, name in enumerate(class_names)]\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=True,\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Get class names from the target variable\n",
    "# If your dataframe is still called df\n",
    "class_names = df['prognosis'].unique().tolist()\n",
    "class_names = sorted(class_names)  # Ensure correct order\n",
    "\n",
    "# Evaluate the model\n",
    "save_path = \"../report/knn/confusion_matrix.png\"\n",
    "evaluate_model(y_test, y_pred, class_names, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa4eab",
   "metadata": {},
   "source": [
    "## Step 3.2: Optimize the Number of Neighbors (k)\n",
    "\n",
    "K-Nearest Neighbors relies on the `k` parameter ‚Äî the number of nearest neighbors used to classify a new point.\n",
    "\n",
    "Choosing the right `k` is crucial:\n",
    "- **Too small** ‚Üí very sensitive to noise (overfitting).\n",
    "- **Too large** ‚Üí overly smooth predictions (underfitting).\n",
    "\n",
    "In this step, we evaluate multiple values of `k` and visualize their corresponding accuracy scores. Our goal is to select the value of `k` that maximizes accuracy on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f0183",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_values = range(1, 21)\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_k = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred_k)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Plot accuracy vs k\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, accuracies, marker='o')\n",
    "plt.title(\"Accuracy vs. Number of Neighbors (k)\")\n",
    "plt.xlabel(\"Number of Neighbors (k)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"../report/knn/accuracy_vs_k.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a316ed7",
   "metadata": {},
   "source": [
    "## Step 3.3: Final KNN Model & Interpretation\n",
    "\n",
    "After tuning the `k` value, we retrain the model using the **best-performing number of neighbors** and finalize our results.\n",
    "\n",
    "We evaluate this model again to confirm its performance and summarize the key takeaways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222669be",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Final model with best k (replace with your chosen best_k)\n",
    "best_k = k_values[accuracies.index(max(accuracies))]\n",
    "final_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "final_knn.fit(X_train, y_train)\n",
    "final_preds = final_knn.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"‚úÖ Final KNN model trained with k = {best_k}\")\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(y_test, final_preds))\n",
    "\n",
    "# Generate new confusion matrix\n",
    "evaluate_model(y_test, final_preds, class_names, save_path=\"../report/knn/final_confusion_matrix.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c882a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Generate the classification report as a dictionary\n",
    "report = classification_report(y_test, final_preds, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Convert it to a DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Round for better readability\n",
    "df_report = df_report.round(3)\n",
    "\n",
    "# Display the table\n",
    "display(df_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa270274",
   "metadata": {},
   "source": [
    "## Step 4: Disease Prediction Using Decision Tree Classifier\n",
    "\n",
    "In this step, we train a **Decision Tree classifier** to predict patient diagnoses based on their symptoms and environmental conditions.\n",
    "\n",
    "### What is a Decision Tree?\n",
    "\n",
    "A **Decision Tree** is a supervised learning model that makes predictions by learning a series of **if-else rules** from the data. The model recursively splits the dataset based on feature values that best separate the classes. The resulting structure is a flowchart-like tree, where:\n",
    "\n",
    "- **Internal nodes** represent decisions based on feature thresholds (e.g., \"Is temperature > 38¬∞C?\").\n",
    "- **Branches** represent possible outcomes of a decision.\n",
    "- **Leaf nodes** represent the final predicted class (diagnosis).\n",
    "\n",
    "This model is highly interpretable ‚Äî clinicians can trace back the reasoning behind each prediction by following the tree path.\n",
    "\n",
    "### Why Use a Decision Tree Here?\n",
    "\n",
    "In our context, Decision Trees are a good fit because:\n",
    "\n",
    "- They can naturally handle both **binary symptoms** and **continuous weather features**.\n",
    "- They can capture **nonlinear interactions** between symptoms and conditions.\n",
    "- The tree structure provides an **explainable model**, which is desirable in healthcare applications.\n",
    "- They allow us to identify which features (symptoms, age, weather) are most important for predicting each disease.\n",
    "\n",
    "### Workflow\n",
    "\n",
    "We will:\n",
    "1. Train a Decision Tree model on our dataset.\n",
    "2. Evaluate its predictive performance.\n",
    "3. Visualize the learned tree structure to inspect how the model makes decisions.\n",
    "4. Compare its performance.\n",
    "\n",
    "### Limitations of Decision Trees\n",
    "\n",
    "While Decision Trees offer excellent interpretability, they also come with some limitations:\n",
    "\n",
    "- **Overfitting**: A fully grown tree may fit the training data perfectly but perform poorly on new data. Pruning or limiting the tree depth (e.g., `max_depth`) is often required to avoid this.\n",
    "- **Instability**: Small changes in the data can lead to very different tree structures, as the tree-building process is greedy.\n",
    "- **Bias toward features with more levels**: Features with more unique values may dominate splits, even if they are not truly more informative.\n",
    "- **Lower predictive power** compared to ensemble methods (such as Random Forest or Gradient Boosted Trees), which combine multiple trees to improve accuracy and robustness.\n",
    "\n",
    "Despite these limitations, Decision Trees remain a valuable tool for **interpretable baseline models** and for understanding the structure of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9cb69",
   "metadata": {},
   "source": [
    "## Step 4.1: Train the Decision Tree Classifier\n",
    "\n",
    "We first initialize and train a **Decision Tree classifier** using the training set.\n",
    "\n",
    "At this stage, we use default hyperparameters, meaning the tree will grow fully to fit the data. We will later explore how controlling the tree depth can help improve generalization.\n",
    "\n",
    "Training a Decision Tree involves the model learning **splitting rules** that divide the feature space into regions associated with each disease class.\n",
    "\n",
    "We then generate predictions on the test set to evaluate the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605efda",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "dt_pred = dt_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed96d21",
   "metadata": {},
   "source": [
    "## Step 4.2: Evaluate the Decision Tree Model\n",
    "\n",
    "We evaluate the Decision Tree classifier using the following metrics:\n",
    "\n",
    "- **Accuracy**: Overall proportion of correct predictions.\n",
    "- **Precision / Recall / F1-Score**: Detailed per-class evaluation of model performance.\n",
    "- **Confusion Matrix**: Visual breakdown of true vs. predicted labels.\n",
    "\n",
    "These metrics help us understand how well the model performs across different disease classes and whether it tends to favor certain predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073dcc59",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Use correct class names from your dataframe\n",
    "class_names = sorted(df['prognosis'].unique().tolist())\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "save_path = \"../report/decision_tree/confusion_matrix.png\"\n",
    "evaluate_model(y_test, dt_pred, class_names, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561f2c8",
   "metadata": {},
   "source": [
    "## Step 4.3: Visualize the Decision Tree\n",
    "\n",
    "One of the main advantages of Decision Trees is their **interpretability**. The trained model can be visualized as a tree structure where:\n",
    "\n",
    "- Each **internal node** represents a decision based on a feature.\n",
    "- Each **branch** corresponds to the outcome of that decision.\n",
    "- Each **leaf node** represents a predicted disease class.\n",
    "\n",
    "Visualizing the tree helps us understand **which symptoms and environmental factors** are most important for predicting each disease. It also allows us to inspect the logical structure of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c0b55",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the full Decision Tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_model, \n",
    "          feature_names=df.drop(columns=[\"prognosis\"]).columns.tolist(),\n",
    "          class_names=class_names, \n",
    "          filled=True, \n",
    "          fontsize=8)\n",
    "\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to report\n",
    "plt.savefig(\"../report/decision_tree/decision_tree_plot.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0049f3",
   "metadata": {},
   "source": [
    "## Step 4.4: Tune the Maximum Depth of the Tree\n",
    "\n",
    "Fully grown Decision Trees tend to **overfit** the training data, resulting in very large and complex trees that are difficult to interpret.\n",
    "\n",
    "By limiting the tree's maximum depth (`max_depth` parameter), we can:\n",
    "\n",
    "- Improve generalization to unseen data.\n",
    "- Produce a simpler and more readable tree.\n",
    "- Focus on the most important decision paths.\n",
    "\n",
    "Here, we retrain the model with `max_depth = [4,8,12,16,20]` to produce a more interpretable structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f0248",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Retrain Decision Tree with limited depth\n",
    "max_depths = [4,8,12,16,20]\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    dt_model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    save_path = f\"../report/decision_tree/confusion_matrix_maxdepth{max_depth}.png\"\n",
    "    evaluate_model(y_test, dt_pred, class_names, save_path)\n",
    "    \n",
    "    # Visualize the tree\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(dt_model, \n",
    "              feature_names=df.drop(columns=[\"prognosis\"]).columns.tolist(),\n",
    "              class_names=class_names, \n",
    "              filled=True, \n",
    "              fontsize=8)\n",
    "    \n",
    "    plt.title(f\"Decision Tree Visualization (max_depth={max_depth})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../report/decision_tree/decision_tree_plot_maxdepth{max_depth}.png\", dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb471bdc",
   "metadata": {},
   "source": [
    "## Step 4.5: Effect of Maximum Tree Depth on Model Performance\n",
    "\n",
    "To better understand how the depth of the Decision Tree affects its predictive power, we conduct an experiment by training trees with different `max_depth` values.\n",
    "\n",
    "This allows us to observe the trade-off between:\n",
    "\n",
    "- **Model Complexity**: Deeper trees can model more complex patterns but are prone to overfitting.\n",
    "- **Interpretability**: Shallower trees are easier to understand but may underfit the data.\n",
    "- **Accuracy**: How predictive performance varies as we change the depth.\n",
    "\n",
    "We evaluate accuracy on the test set for several values of `max_depth` and visualize the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbdaf57",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Range of max_depth values to test\n",
    "depth_values = [2, 3, 4, 5, 6, 8, 10, 12, 15, None]  # None = full depth\n",
    "\n",
    "# Store results\n",
    "depth_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for depth in depth_values:\n",
    "    # Train Decision Tree\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred_depth = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_test, y_pred_depth)\n",
    "    \n",
    "    # Store results\n",
    "    depth_list.append(\"Full\" if depth is None else depth)\n",
    "    accuracy_list.append(acc)\n",
    "    \n",
    "    print(f\"max_depth = {depth}: accuracy = {acc:.4f}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(depth_list, accuracy_list, marker='o', linestyle='-')\n",
    "plt.title(\"Effect of Decision Tree max_depth on Accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to report\n",
    "plt.savefig(\"../report/decision_tree/max_depth_optimization.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d52751",
   "metadata": {},
   "source": [
    "## Conclusion of Decision Tree Modeling\n",
    "\n",
    "In this section, we trained a Decision Tree classifier to predict diseases based on patient symptoms and environmental factors.\n",
    "\n",
    "- The full tree (no depth limit) achieved very high accuracy (**97.19%**) but produced a very large and complex tree, prone to overfitting.\n",
    "- We systematically evaluated different values of `max_depth`, observing the trade-off between model complexity and performance:\n",
    "\n",
    "| max_depth | Accuracy (%) |\n",
    "|-----------|--------------|\n",
    "| 2         | 40.12        |\n",
    "| 3         | 44.93        |\n",
    "| 4         | 48.85        |\n",
    "| 5         | 53.16        |\n",
    "| 6         | 56.47        |\n",
    "| 8         | 63.89        |\n",
    "| 10        | 70.51        |\n",
    "| 12        | 75.53        |\n",
    "| 15        | 84.15        |\n",
    "| Full      | 97.19        |\n",
    "\n",
    "- As expected, shallow trees (e.g., `max_depth=2` to `4`) offered high interpretability but suffered from low accuracy (underfitting).\n",
    "- Deeper trees progressively improved accuracy, but at the cost of producing much larger and less interpretable models.\n",
    "\n",
    "From the visualization at `max_depth=4`, we observed that:\n",
    "\n",
    "- `chest_pain` and `hiv_aids` were highly informative and appeared at the top of the tree.\n",
    "- Features such as `diarrhea`, `headache`, and `trouble_seeing` also contributed to differentiating certain diseases.\n",
    "\n",
    "This experiment clearly illustrates the **performance vs. interpretability trade-off** inherent to Decision Trees.\n",
    "\n",
    "Overall, Decision Trees provide a transparent and useful baseline model for our medical prediction task, especially when explainability is required.\n",
    "\n",
    "In the next step, we will explore ensemble classifiers (Random Forest, Gradient Boosted Trees) to aim for **higher predictive power** while analyzing feature importance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7900dcc",
   "metadata": {},
   "source": [
    "## Step 5.1: Increasing Predictive Power Using Ensemble Classifiers\n",
    "\n",
    "We've now built individual decision trees to predict diseases based on environmental factors. While the decision trees can intuitive and easy to interpret, by varying the depth we often suffer from either poor interpretability or poor accuracy, leading to poor generalization on unseen data. This is where ensemble methods like Random Forest and XGBoost come into play, significantly boosting predictive power by combining multiple decision trees.\n",
    "\n",
    "Instead of one deep, overfit tree, Random Forest builds many (e.g., hundreds) independent decision trees. Each of these trees is intentionally \"overfit\" to a subset of the data (bootstrap samples) and only considers a random subset of features at each split. By averaging or majority-voting the predictions of these many diverse, slightly biased trees, the collective decision becomes far more robust and generalized. The individual errors and idiosyncrasies of each tree cancel out, leading to a significant reduction in variance and, consequently, preventing the severe overfitting we observed with the single full tree.\n",
    "\n",
    "While also using many trees, Gradient Boosting tackles overfitting differently. It builds trees sequentially, with each new tree trying to correct the prediction errors (residuals) of the previous trees. This iterative refinement allows the model to progressively learn more complex patterns and focus on the data points that were difficult for earlier trees. Despite building on potentially \"weak learners,\" the cumulative effect, combined with built-in regularization techniques (which XGBoost is particularly good at), leads to extremely strong and well-generalized models, mitigating the risk of overfitting found in a single deep tree. \n",
    "\n",
    "## Step 5.2: Utilizing Random Forest \n",
    "\n",
    "Now we can utilize the X and Y training sets that we defined earlier to train a Random Forest Classifier in order to potentially solve our problem with overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6442ee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b46f5",
   "metadata": {},
   "source": [
    "For clarity, here is a visual of one possible random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2039dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(clf.estimators_[0], \n",
    "          filled=True, \n",
    "          feature_names=feature_names, \n",
    "          class_names=class_names, \n",
    "          rounded=True, \n",
    "          proportion=False, \n",
    "          precision=2)\n",
    "plt.title(\"Visualization of One Tree from the Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316422a",
   "metadata": {},
   "source": [
    "And then we can create some predictions in order to evaluate the performance of the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da477dfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb082726",
   "metadata": {},
   "source": [
    "## Step 5.3: Evaluating Random Forest\n",
    "\n",
    "We can use accuracy, a conversion matrix, Precision, recall, F1-score, and ROC-AUC to evaluate the performance of our random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d32a4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 1. Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# 4. ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "\n",
    "# 5. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a8e57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca206b6",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fa1c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", decision_function_shape=\"ovr\", random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fc52f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict on test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759553a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
